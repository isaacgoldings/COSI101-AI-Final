{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f8016590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "26c454c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDatasetFromImages(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        # First column contains the image paths\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        # Second column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = self.image_arr[index]\n",
    "        # Open image\n",
    "        img_as_img = Image.open(\"data/training/\"+single_image_name)\n",
    "\n",
    "        t = transforms.Resize((20,57))\n",
    "        \n",
    "        img_as_img = t(img_as_img)\n",
    "        \n",
    "        # Transform image to tensor\n",
    "        img_as_tensor = self.to_tensor(img_as_img)\n",
    "\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.label_arr[index]\n",
    "        \n",
    "        single_image_label = torch.tensor([single_image_label], dtype=torch.long)\n",
    "        \n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    # Call dataset\n",
    "#    custom_mnist_from_images =  \\\n",
    "#        CustomDatasetFromImages('data/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d94b9506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "         [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "         [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "         ...,\n",
      "         [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "         [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882],\n",
      "         [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882]]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [236]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m57\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m             rowtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][x][z]\n\u001b[1;32m     25\u001b[0m corner_avg \u001b[38;5;241m=\u001b[39m rowtotal\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m860\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# all columns offset by one\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# columns\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# first = 0.9527\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# 5-33 57\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# 5-14 20\u001b[39;00m\n",
      "Input \u001b[0;32mIn [234]\u001b[0m, in \u001b[0;36mTrainDatasetFromImages.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m img_as_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/training/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39msingle_image_name)\n\u001b[1;32m     26\u001b[0m t \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m57\u001b[39m))\n\u001b[0;32m---> 28\u001b[0m img_as_img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_as_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Transform image to tensor\u001b[39;00m\n\u001b[1;32m     31\u001b[0m img_as_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_tensor(img_as_img)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/transforms.py:349\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/functional.py:436\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    434\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    435\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39msize, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, max_size\u001b[38;5;241m=\u001b[39mmax_size, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/functional_pil.py:265\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_size should only be passed if size specifies the length of the smaller edge, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi.e. size should be an int or a sequence of length 1 in torchscript mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m     )\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/Image.py:1989\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1986\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mresize(size, resample, box)\n\u001b[1;32m   1987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m-> 1989\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reducing_gap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resample \u001b[38;5;241m!=\u001b[39m NEAREST:\n\u001b[1;32m   1992\u001b[0m     factor_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m reducing_gap) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/ImageFile.py:237\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecodermaxblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, struct\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;66;03m# truncated png/gif\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m LOAD_TRUNCATED_IMAGES:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/PIL/PngImagePlugin.py:888\u001b[0m, in \u001b[0;36mPngImageFile.load_read\u001b[0;34m(self, read_bytes)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__prepare_idat  \u001b[38;5;66;03m# used by load_read()\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     ImageFile\u001b[38;5;241m.\u001b[39mImageFile\u001b[38;5;241m.\u001b[39mload_prepare(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, read_bytes):\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;124;03m\"\"\"internal: read more image data\"\"\"\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__idat \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;66;03m# end of chunk, skip forward to next one\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = TrainDatasetFromImages('data/training/labels-tab-csv.csv')\n",
    "print(train_data[6][0])\n",
    "# plt.imshow(train_data[0][0].numpy().squeeze(), cmap='gray_r');\n",
    "# for index in range(0, 10):\n",
    "#     plt.imshow(train_data[index][0].numpy().squeeze(), cmap='gray_r');\n",
    "\n",
    " # print(train_data[2][0][0][19][56])\n",
    "\n",
    "# [imageIndex][][][row][column]\n",
    "\n",
    "rowtotal = 0\n",
    "\n",
    "# width 1, height = 20 for 20 diff rows\n",
    "w, h = 1, 20\n",
    "\n",
    "Matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "# Matrix[0][0] = 1\n",
    "\n",
    "for i in range(0,860):\n",
    "    for x in range(0,20):\n",
    "        for z in range(0,57):\n",
    "            rowtotal += train_data[i][0][0][x][z]\n",
    "    \n",
    "corner_avg = rowtotal/(860*20)\n",
    "\n",
    "# all columns offset by one\n",
    "# columns\n",
    "# first = 0.9527\n",
    "# second = 0.9525\n",
    "# 3rd = 0.9523\n",
    "# 4th = 0.9516\n",
    "# 5th = 0.9501\n",
    "# 6th = 0.9481\n",
    "# eleventh = 0.9399\n",
    "\n",
    "# fourteenth = 0.9359\n",
    "# sixteenth = 0.9312\n",
    "# seventeenth = 0.9295\n",
    "# eighteenth = 0.9293\n",
    "# nineteenth = 0.9275\n",
    "# twentieth = 0.9272\n",
    "# 21st = 0.9268\n",
    "# 22nd = 0.9260\n",
    "# 23rd = 0.9241\n",
    "# 24th = 0.9262\n",
    "# 25th = 0.9293\n",
    "# 26th = 0.9324\n",
    "# 27th = 0.9347\n",
    "# 28th = 0.9377\n",
    "# 29th = 0.9410\n",
    "# 30th = 0.9448\n",
    "# 31st = 0.9467\n",
    "# 32nd = 0.9480\n",
    "# 33rd = 0.9495\n",
    "\n",
    "# 5 through 33 of 57\n",
    "# top and bottom 5 for rows of 20\n",
    "\n",
    "# 5-33 57\n",
    "# 5-14 20\n",
    "\n",
    "\n",
    "print(corner_avg)\n",
    "# figure = plt.figure()\n",
    "# num_of_images = 60\n",
    "# for index in range(1, num_of_images + 1):\n",
    "#     plt.subplot(6, 10, index)\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "510a2157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9882, 0.9922,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9765, 0.7725, 0.7804,\n",
      "         0.9922, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9961, 0.9294, 0.7216,\n",
      "         0.9882, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9961, 0.8784, 0.5922, 0.6667,\n",
      "         0.9098, 0.9961, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.9922, 0.8824, 0.7725, 0.9137, 0.8235, 0.8235, 0.8902, 0.9216,\n",
      "         0.9647, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 0.9882, 0.8627, 0.7255, 0.4863, 0.7098, 0.9647, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.9922, 0.8000, 0.5961, 0.7569, 0.9020, 0.9686, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.9882, 0.8980, 0.9725, 0.8863, 0.8353, 0.9529, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(train_data[0])\n",
    "# print(train_data[0][0][:,5:15,5:33])\n",
    "plt.imshow(train_data[0][0][:,5:15,5:33].numpy().squeeze(), cmap='gray_r');\n",
    "\n",
    "\n",
    "myArray = []\n",
    "for i in range(860):\n",
    "    myArray.append(train_data[i][0][:,5:15,5:33])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# print(train_data.shape)\n",
    "print(myArray[0][0])\n",
    "\n",
    "plt.imshow(train_data[0][0].numpy().squeeze(), cmap='gray_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5187f81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00000000e+000  1.13635099e-322  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  ...\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  1.65780921e-316 ...\n",
      "    0.00000000e+000  0.00000000e+000  2.93617426e-294]\n",
      "  [-1.61999263e-253 -7.15395676e+303  1.65778401e-316 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]]\n",
      "\n",
      " [[ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  4.24399158e-314]\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    4.59089227e+214 -9.44733742e-004  7.29112908e-304]\n",
      "  [ 7.29112205e-304  1.26480805e-321  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  ...\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]]\n",
      "\n",
      " [[ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  9.88131292e-324 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  ...\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      "  [ 0.00000000e+000  0.00000000e+000  0.00000000e+000 ...\n",
      "    0.00000000e+000  0.00000000e+000  0.00000000e+000]]]\n",
      "(tensor([[[0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],\n",
      "         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],\n",
      "         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],\n",
      "         ...,\n",
      "         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],\n",
      "         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],\n",
      "         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922]]]), tensor([1]))\n"
     ]
    }
   ],
   "source": [
    "arr = np.empty([3,57,20])\n",
    "print(arr)\n",
    "print(train_data[0])\n",
    "# for i in range(860):\n",
    "#     arr[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8b1226c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4560\n"
     ]
    }
   ],
   "source": [
    "print(arr.size)\n",
    "# [row][col][value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "29f9bd87",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [212]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m33\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "Input \u001b[0;32mIn [184]\u001b[0m, in \u001b[0;36mTrainDatasetFromImages.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Get image name from the pandas df\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     single_image_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_arr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Open image\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     img_as_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/training/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39msingle_image_name)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "train_data2 = train_data[:,5:15, 5:33]\n",
    "# print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "193f3220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# width 1, height = 20 for 20 diff rows\n",
    "w, h = 1, 20\n",
    "\n",
    "Matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "# Matrix[0][0] = 1\n",
    "print(Matrix[4][0])\n",
    "\n",
    "train_data = TrainDatasetFromImages('data/training/labels-tab-csv.csv')\n",
    "# rowtotal = 0\n",
    "\n",
    "# for i in range(0,860):\n",
    "#     for x in range(0,20):\n",
    "#         for z in range(0,57):\n",
    "#             rowtotal += train_data[i][0][0][x][z]\n",
    "#         Matrix[x][0] += rowtotal\n",
    "#         rowtotal = 0\n",
    "    \n",
    "# for a in range(0,20):\n",
    "#     print(Matrix[x][0]/860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "29b4a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0541)\n",
      "tensor(0.0534)\n",
      "tensor(0.0517)\n",
      "tensor(0.0514)\n",
      "tensor(0.0486)\n",
      "tensor(0.0511)\n",
      "tensor(0.0544)\n",
      "tensor(0.0576)\n",
      "tensor(0.0613)\n",
      "tensor(0.0644)\n",
      "tensor(0.0657)\n",
      "tensor(0.0637)\n",
      "tensor(0.0588)\n",
      "tensor(0.0538)\n",
      "tensor(0.0502)\n",
      "tensor(0.0487)\n",
      "tensor(0.0522)\n",
      "tensor(0.0521)\n",
      "tensor(0.0548)\n",
      "tensor(0.0541)\n"
     ]
    }
   ],
   "source": [
    "for a in range(0,20):\n",
    "    print(1-Matrix[a][0]/(57*860))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4bea7c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[1][0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dacf38fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[2][0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "74fbabd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[3][0].numpy().squeeze(), cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e7e63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1140\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 11 #might be an issue\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ae0f451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 57])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1140]) torch.Size([1])\n",
      "Epoch 0 - Training loss: 2.3071336826612785\n",
      "Epoch 1 - Training loss: 2.3071011745652488\n",
      "Epoch 2 - Training loss: 2.3070834841839103\n",
      "Epoch 3 - Training loss: 2.3070655387501384\n",
      "Epoch 4 - Training loss: 2.3070479090823683\n",
      "Epoch 5 - Training loss: 2.3070305322491844\n",
      "Epoch 6 - Training loss: 2.3070135130438696\n",
      "Epoch 7 - Training loss: 2.3069967364155968\n",
      "Epoch 8 - Training loss: 2.3069802749988644\n",
      "Epoch 9 - Training loss: 2.3069640927536543\n",
      "Epoch 10 - Training loss: 2.306948155303334\n",
      "Epoch 11 - Training loss: 2.306932526133781\n",
      "Epoch 12 - Training loss: 2.3069171179172603\n",
      "Epoch 13 - Training loss: 2.306901979446411\n",
      "Epoch 14 - Training loss: 2.306887099909228\n",
      "\n",
      "Training Time (in minutes) = 0.3918490688006083\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(train_data))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images) \n",
    "print(images.shape, labels.shape)\n",
    "\n",
    "\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 15\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_data:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(train_data)))\n",
    "\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa81c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Number Of Images Tested = 860\n",
      "\n",
      "Model Accuracy = 0.1\n"
     ]
    }
   ],
   "source": [
    "valloader = TrainDatasetFromImages('data/training/labels-tab-csv.csv')\n",
    "\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 1140)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    print(pred_label)\n",
    "    \n",
    "    true_label = labels.numpy()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6fbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f778c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
