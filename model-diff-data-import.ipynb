{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8016590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a0d5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 859/859 [00:05<00:00, 163.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(859, 60, 171)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/training/labels-tab-csv.csv')\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "image_arr = np.asarray(train.iloc[:, 0])\n",
    "label_arr = np.asarray(train.iloc[:, 1])\n",
    "\n",
    "train_img = []\n",
    "for img_name in tqdm(image_arr):\n",
    "    # defining the image path\n",
    "    image_path = 'data/training/' + str(img_name)\n",
    "    # reading the image\n",
    "    img = imread(image_path, as_gray=True)\n",
    "    \n",
    "  #  t = transforms.Resize(60, 171)\n",
    "    img = resize(img, (60, 171),\n",
    "                       anti_aliasing=True)\n",
    "\n",
    "    # normalizing the pixel values\n",
    " #   img /= 255.0\n",
    "    img = np.true_divide(img, 255) #avoid division error\n",
    "    # converting the type of pixel to float 32\n",
    "    img = img.astype('float32')\n",
    "    # appending the image into the list\n",
    "    train_img.append(img)\n",
    "\n",
    "# converting the list to numpy array\n",
    "train_x = np.array(train_img)\n",
    "# defining the target\n",
    "train_y = label_arr\n",
    "\n",
    "\n",
    "train_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31bf253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((773, 60, 171), (773,)), ((86, 60, 171), (86,)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.1)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14506f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x.reshape(773, 1, 60, 171)\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "\n",
    "train_y = train_y.astype(int);\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "\n",
    "train_y = train_y.to(torch.long)\n",
    "# shape of training data\n",
    "train_x.shape, train_y.shape\n",
    "print(train_x[0].dtype)\n",
    "print(train_y[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40d0e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "val_x = val_x.reshape(86, 1, 60, 171)\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int);\n",
    "val_y = torch.from_numpy(val_y)\n",
    "\n",
    "val_y = val_y.to(torch.long)\n",
    "# shape of validation data\n",
    "val_x.shape, val_y.shape\n",
    "print(val_x.dtype)\n",
    "print(val_y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7609ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDatasetFromImages(Dataset):\n",
    "    def __init__(self, img, vals):\n",
    "        self.img = img\n",
    "        self.vals = vals\n",
    "    def __getitem__(self, index):\n",
    "        img1 = self.img[index]\n",
    "        label1 = self.vals[index]\n",
    "        label1 = torch.tensor([label1], dtype=torch.long)\n",
    "        return (img1, label1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af0c7983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         ...,\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "         [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039]]]), tensor([3]))\n"
     ]
    }
   ],
   "source": [
    "train_data = TrainDatasetFromImages(train_x, train_y)\n",
    "print(train_data[0])\n",
    "input_size = 10260\n",
    "hidden_sizes = [250]\n",
    "output_size = 11 #might be an issue\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(train_data))\n",
    "images = images.reshape(images.shape[0], -1)\n",
    "logps = model(images) \n",
    "print(images.shape, labels.shape)\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.91)\n",
    "time0 = time()\n",
    "epochs = 15\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_data:\n",
    "        images = images.reshape(images.shape[0], -1)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(train_x)))\n",
    "\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valloader = TrainDatasetFromImages('data/training/labels-tab-csv.csv')\n",
    "\n",
    "correct_count, all_count = 0, 0\n",
    "for images,labels in train_data:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].reshape(1, 2520)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    #print(pred_label)\n",
    "    \n",
    "    true_label = labels.numpy()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e63a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0f451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
